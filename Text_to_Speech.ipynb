{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univeral Code Used for the Entire Notebook\n",
    "\n",
    "Let's set up our libraries and client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary packages for handling sound files and sound devices\n",
    "# Uncomment the following line if you need to install the packages\n",
    "# !pip install pyaudio\n",
    "# !pip install --upgrade openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  # For interacting with the operating system\n",
    "import requests  # For making HTTP requests\n",
    "from io import BytesIO  # For handling byte streams\n",
    "from pathlib import Path  # For filesystem path manipulations\n",
    "\n",
    "import pyaudio  # For handling audio playback and recording\n",
    "\n",
    "from IPython.display import Audio, display, clear_output, Markdown, HTML  # For displaying content in Jupyter Notebooks\n",
    "\n",
    "from openai import OpenAI, AssistantEventHandler  # For OpenAI API and event handling\n",
    "from typing_extensions import override  # For method overriding in subclasses\n",
    "\n",
    "import time  # For time-related functions\n",
    "import threading  # For handling threads\n",
    "import queue  # For creating and managing queues\n",
    "import re  # For regular expressions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the OpenAI client\n",
    "client = OpenAI()  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating an Audio File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the openai api library approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio saved to ./fight_on_the_beaches.mp3\n"
     ]
    }
   ],
   "source": [
    "# Define the speech file path\n",
    "speech_file_path = \"./fight_on_the_beaches.mp3\"\n",
    "\n",
    "# Create the TTS (Text-to-Speech) request\n",
    "response = client.audio.speech.create(\n",
    "    model=\"tts-1-hd\",  # Specify the TTS model to use\n",
    "    voice=\"fable\",  # Specify the voice to use for the TTS\n",
    "    input=\"\"\"\n",
    "    Even though large tracts of Europe and many old and famous States have fallen or may fall into the grip of the Gestapo and all the odious apparatus of Nazi rule, we shall not flag or fail. We shall go on to the end, we shall fight in France, we shall fight on the seas and oceans, we shall fight with growing confidence and growing strength in the air, we shall defend our Island, whatever the cost may be, we shall fight on the beaches, we shall fight on the landing grounds, we shall fight in the fields and in the streets, we shall fight in the hills; we shall never surrender, and even if, which I do not for a moment believe, this Island or a large part of it were subjugated and starving, then our Empire beyond the seas, armed and guarded by the British Fleet, would carry on the struggle, until, in God’s good time, the New World, with all its power and might, steps forth to the rescue and the liberation of the old.\n",
    "    \"\"\"  # Input text to be converted to speech\n",
    ")\n",
    "\n",
    "# Save the response audio to a file\n",
    "with open(speech_file_path, 'wb') as file:\n",
    "    file.write(response.content)  # Write the audio content to the file\n",
    "\n",
    "# Print a message indicating where the audio was saved\n",
    "print(f\"Audio saved to {speech_file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the API endpoint approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio saved to ./old_soldiers_never_die.mp3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the speech file path\n",
    "speech_file_path = \"./old_soldiers_never_die.mp3\"\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# API endpoint and headers\n",
    "url = \"https://api.openai.com/v1/audio/speech\"\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {api_key}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "# Data payload for the request\n",
    "data = {\n",
    "    \"model\": \"tts-1\",\n",
    "    \"voice\": \"shimmer\",\n",
    "    \"input\": \"\"\"\n",
    "    I still remember the refrain of one of the most popular barracks ballads of that day which proclaimed most proudly that old soldiers never die; they just fade away. And like the old soldier of that ballad, I now close my military career and just fade away, an old soldier who tried to do his duty as God gave him the light to see that duty.\n",
    "    \"\"\"\n",
    "}\n",
    "\n",
    "# Make the synchronous request\n",
    "response = requests.post(url, headers=headers, json=data)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    with open(speech_file_path, 'wb') as file:\n",
    "        file.write(response.content)\n",
    "    print(f\"Audio saved to {speech_file_path}\")\n",
    "else:\n",
    "    print(f\"Error: {response.status_code} - {response.text}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Chat Completion and Assistant Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chat Completion to Audio without End-to-End Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating response...\n",
      "Response:\n",
      "Four score and seven years ago our fathers brought forth on this continent, a new nation, conceived in Liberty, and dedicated to the proposition that all men are created equal.\n",
      "\n",
      "Now we are engaged in a great civil war, testing whether that nation, or any nation so conceived and so dedicated, can long endure. We are met on a great battle-field of that war. We have come to dedicate a portion of that field, as a final resting place for those who here gave their lives that that nation might live. It is altogether fitting and proper that we should do this.\n",
      "\n",
      "But, in a larger sense, we can not dedicate—we can not consecrate—we can not hallow—this ground. The brave men, living and dead, who struggled here, have consecrated it, far above our poor power to add or detract. The world will little note, nor long remember what we say here, but it can never forget what they did here. It is for us the living, rather, to be dedicated here to the unfinished work which they who fought here have thus far so nobly advanced. It is rather for us to be here dedicated to the great task remaining before us—that from these honored dead we take increased devotion to that cause for which they gave the last full measure of devotion—that we here highly resolve that these dead shall not have died in vain—that this nation, under God, shall have a new birth of freedom—and that government of the people, by the people, for the people, shall not perish from the earth.\n",
      "\n",
      "Converting to speech...\n",
      "Playing audio...\n",
      "Audio playback completed.\n",
      "Process completed.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class AudioPlayer:\n",
    "    def __init__(self):\n",
    "        self.audio_queue = queue.Queue()\n",
    "        self.playback_complete = threading.Event()\n",
    "        self.audio_added = threading.Event()\n",
    "        \n",
    "        # Initialize PyAudio\n",
    "        self.p = pyaudio.PyAudio()\n",
    "        self.stream = self.p.open(format=pyaudio.paInt16,\n",
    "            channels=1,\n",
    "            rate=24000,\n",
    "            output=True)\n",
    "        \n",
    "        # Start audio playback thread\n",
    "        self.audio_thread = threading.Thread(target=self.play_audio)\n",
    "        self.audio_thread.start()\n",
    "\n",
    "    def play_audio(self):\n",
    "        while not self.playback_complete.is_set():\n",
    "            try:\n",
    "                audio_chunk = self.audio_queue.get(timeout=0.1)\n",
    "                self.stream.write(audio_chunk)\n",
    "            except queue.Empty:\n",
    "                if self.audio_added.is_set() and self.audio_queue.empty():\n",
    "                    # If all audio has been added and queue is empty, we're done\n",
    "                    break\n",
    "                continue\n",
    "\n",
    "        self.stream.stop_stream()\n",
    "        self.stream.close()\n",
    "        self.p.terminate()\n",
    "        print(\"Audio playback completed.\")\n",
    "\n",
    "    def add_audio(self, audio_data):\n",
    "        for chunk in audio_data:\n",
    "            self.audio_queue.put(chunk)\n",
    "        self.audio_added.set()  # Signal that all audio has been added\n",
    "\n",
    "    def wait_for_completion(self):\n",
    "        self.audio_thread.join()\n",
    "\n",
    "def get_chat_completion(prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def text_to_speech(text):\n",
    "    audio_response = client.audio.speech.create(\n",
    "        model=\"tts-1\",\n",
    "        voice=\"onyx\",\n",
    "        input=text,\n",
    "        response_format=\"pcm\"\n",
    "    )\n",
    "    return audio_response.iter_bytes(chunk_size=1024)\n",
    "\n",
    "# Main execution\n",
    "prompt = \"Give me the entire Gettysburg Address from Abraham Lincoln. JUST the address, not any additional text before or after. Do not add a reply just give me the text of the address.\"\n",
    "print(\"Generating response...\")\n",
    "response_text = get_chat_completion(prompt)\n",
    "\n",
    "print(\"Response:\")\n",
    "print(response_text)\n",
    "\n",
    "print(\"\\nConverting to speech...\")\n",
    "audio_data = text_to_speech(response_text)\n",
    "\n",
    "print(\"Playing audio...\")\n",
    "player = AudioPlayer()\n",
    "player.add_audio(audio_data)\n",
    "\n",
    "# Wait for audio to finish playing\n",
    "player.wait_for_completion()\n",
    "\n",
    "print(\"Process completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assistant to Audio without End-to-end Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating response from assistant...\n",
      "Response:\n",
      "ゲティスバーグ演説（日本語訳）\n",
      "\n",
      "87年前、われわれの父祖たちはこの大陸に自由を尊び、すべての人々が平等に創られているという信条をもとに、新しい国を誕生させた。今、われわれは内戦のさなかにあり、この国、あるいはその他の国々がそうであったように、長く続くことができるのかどうかの重大な試練の中にある。われわれはこの戦争の大いなる戦場に集まっている。われわれはこの戦場の一角を捧げ、これをここで戦った者たちにとって最後の安息の地とし、彼らの命を捧げて聖別しようとしている。われわれはむしろ、ここに残る生者としての大きな任務を心に刻もう。この戦争を務め上げた彼らの崇高な犠牲に負けぬよう、われわれ自身もまたその任務を全うするという誓いを新たにしよう。彼らが尊い犠牲を払って得た自由のもとに、われわれは新たな決意を持って臨むことを誓う。そして、彼らの死を草しないためにも、この国に神のもと新たなる自由が生まれること、そして人民の、人民による、人民のための政治が地上から消え去ることが決してないようにすることを、われわれはここに誓うのである。\n",
      "\n",
      "Converting to speech...\n",
      "Playing audio...\n",
      "Audio playback completed.\n",
      "Process completed.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class AudioPlayer:\n",
    "    \"\"\"\n",
    "    A class to handle audio playback using PyAudio.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.audio_queue = queue.Queue()  # Queue to store audio chunks\n",
    "        self.playback_complete = threading.Event()  # Event to signal playback completion\n",
    "        self.audio_added = threading.Event()  # Event to signal that audio has been added to the queue\n",
    "\n",
    "        # Initialize PyAudio\n",
    "        self.p = pyaudio.PyAudio()\n",
    "        self.stream = self.p.open(\n",
    "            format=pyaudio.paInt16,\n",
    "            channels=1,\n",
    "            rate=24000,\n",
    "            output=True\n",
    "        )\n",
    "\n",
    "        # Start audio playback thread\n",
    "        self.audio_thread = threading.Thread(target=self.play_audio)\n",
    "        self.audio_thread.start()\n",
    "\n",
    "    def play_audio(self):\n",
    "        \"\"\"\n",
    "        Method to play audio chunks from the queue.\n",
    "        \"\"\"\n",
    "        while not self.playback_complete.is_set():\n",
    "            try:\n",
    "                audio_chunk = self.audio_queue.get(timeout=0.1)\n",
    "                self.stream.write(audio_chunk)\n",
    "            except queue.Empty:\n",
    "                if self.audio_added.is_set() and self.audio_queue.empty():\n",
    "                    # If all audio has been added and queue is empty, we're done\n",
    "                    break\n",
    "                continue\n",
    "\n",
    "        self.stream.stop_stream()\n",
    "        self.stream.close()\n",
    "        self.p.terminate()\n",
    "        print(\"Audio playback completed.\")\n",
    "\n",
    "    def add_audio(self, audio_data):\n",
    "        \"\"\"\n",
    "        Method to add audio data to the queue.\n",
    "        \"\"\"\n",
    "        for chunk in audio_data:\n",
    "            self.audio_queue.put(chunk)\n",
    "        self.audio_added.set()  # Signal that all audio has been added\n",
    "\n",
    "    def wait_for_completion(self):\n",
    "        \"\"\"\n",
    "        Method to wait for the audio playback thread to complete.\n",
    "        \"\"\"\n",
    "        self.audio_thread.join()\n",
    "\n",
    "def get_assistant_response(prompt):\n",
    "    \"\"\"\n",
    "    Function to get a response from the OpenAI assistant.\n",
    "    \"\"\"\n",
    "    # Create an assistant\n",
    "    assistant = client.beta.assistants.create(\n",
    "        model=\"gpt-4o\",\n",
    "        instructions=\"You are a helpful assistant.\",\n",
    "        name=\"My Speaking Assistant (No Streaming)\"\n",
    "    )\n",
    "\n",
    "    # Create a thread\n",
    "    thread = client.beta.threads.create()\n",
    "\n",
    "    # Add a message to the thread\n",
    "    client.beta.threads.messages.create(\n",
    "        thread_id=thread.id,\n",
    "        role=\"user\",\n",
    "        content=prompt\n",
    "    )\n",
    "\n",
    "    # Run the assistant\n",
    "    run = client.beta.threads.runs.create(\n",
    "        thread_id=thread.id,\n",
    "        assistant_id=assistant.id\n",
    "    )\n",
    "\n",
    "    # Wait for the run to complete\n",
    "    while True:\n",
    "        run_status = client.beta.threads.runs.retrieve(\n",
    "            thread_id=thread.id,\n",
    "            run_id=run.id\n",
    "        )\n",
    "        if run_status.status == 'completed':\n",
    "            break\n",
    "        time.sleep(1)\n",
    "\n",
    "    # Retrieve the messages\n",
    "    messages = client.beta.threads.messages.list(thread_id=thread.id)\n",
    "\n",
    "    # Get the last assistant message\n",
    "    for message in messages.data:\n",
    "        if message.role == \"assistant\":\n",
    "            return message.content[0].text.value\n",
    "\n",
    "def text_to_speech(text):\n",
    "    \"\"\"\n",
    "    Function to convert text to speech using the OpenAI TTS model.\n",
    "    \"\"\"\n",
    "    audio_response = client.audio.speech.create(\n",
    "        model=\"tts-1\",\n",
    "        voice=\"onyx\",\n",
    "        input=text,\n",
    "        response_format=\"pcm\"\n",
    "    )\n",
    "    return audio_response.iter_bytes(chunk_size=1024)\n",
    "\n",
    "# Main execution\n",
    "prompt = (\n",
    "    \"Give me the entire text of the Gettysburg Address from Abraham Lincoln in Japanese. JUST the address, not any additional text before or after. Do not add a reply just give me the text of the address.\"\n",
    ")\n",
    "print(\"Generating response from assistant...\")\n",
    "response_text = get_assistant_response(prompt)\n",
    "\n",
    "print(\"Response:\")\n",
    "print(response_text)\n",
    "\n",
    "print(\"\\nConverting to speech...\")\n",
    "audio_data = text_to_speech(response_text)\n",
    "\n",
    "print(\"Playing audio...\")\n",
    "player = AudioPlayer()\n",
    "player.add_audio(audio_data)\n",
    "\n",
    "# Wait for audio to finish playing\n",
    "player.wait_for_completion()\n",
    "\n",
    "print(\"Process completed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating an Audio File with Streaming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the openai api library approach\n",
    "\n",
    "(doesn't work)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio saved to ./wonderfulday.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zain\\AppData\\Local\\Temp\\ipykernel_24272\\3293892601.py:12: DeprecationWarning: Due to a bug, this method doesn't actually stream the response content, `.with_streaming_response.method()` should be used instead\n",
      "  response.stream_to_file(speech_file_path)\n"
     ]
    }
   ],
   "source": [
    "# Define the speech file path\n",
    "speech_file_path = \"./wonderfulday.mp3\"\n",
    "\n",
    "# Create the TTS (Text-to-Speech) request\n",
    "response = client.audio.speech.create(\n",
    "    model=\"tts-1\",  # Specify the TTS model to use\n",
    "    voice=\"alloy\",  # Specify the voice to use for the TTS\n",
    "    input=\"Today is a wonderful day to build something people love!\"  # Input text to be converted to speech\n",
    ")\n",
    "\n",
    "# Save the response audio to a file using stream_to_file method\n",
    "response.stream_to_file(speech_file_path)\n",
    "\n",
    "# Print a message indicating where the audio was saved\n",
    "print(f\"Audio saved to {speech_file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the openai api library approach\n",
    "\n",
    "(corrected version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio saved to ./wonderfulday_streaming.mp3\n"
     ]
    }
   ],
   "source": [
    "# Define the speech file path\n",
    "speech_file_path = \"./wonderfulday_streaming.mp3\"\n",
    "\n",
    "# Create the TTS (Text-to-Speech) request using the recommended method\n",
    "with client.audio.speech.with_streaming_response.create(\n",
    "    model=\"tts-1\",\n",
    "    voice=\"alloy\",\n",
    "    input=\"Today is a wonderful day to build something people love!\"\n",
    ") as response:\n",
    "    with open(speech_file_path, 'wb') as f:\n",
    "        for chunk in response.iter_bytes():\n",
    "            f.write(chunk)\n",
    "\n",
    "# Print a message indicating where the audio was saved\n",
    "print(f\"Audio saved to {speech_file_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize PyAudio, which provides bindings for PortAudio, a cross-platform audio library\n",
    "p = pyaudio.PyAudio()\n",
    "\n",
    "# Open a stream with specific audio format parameters\n",
    "stream = p.open(format=pyaudio.paInt16,  # Format: 16-bit PCM (Pulse Code Modulation)\n",
    "                channels=1,              # Channels: 1 (Mono)\n",
    "                rate=24000,              # Sample rate: 24,000 Hz (samples per second)\n",
    "                output=True)             # Stream opened for output (playback)\n",
    "\n",
    "# Function to stream and play audio in real-time\n",
    "def stream_audio():\n",
    "    # Create a TTS (Text-to-Speech) request\n",
    "    with client.audio.speech.with_streaming_response.create(\n",
    "        model=\"tts-1\",                   # Specify the TTS model to use\n",
    "        voice=\"alloy\",                   # Specify the voice to use for TTS\n",
    "        input=\"\"\"\n",
    "    The present German submarine warfare against commerce is a warfare against mankind.\n",
    "\n",
    "    It is war against all nations.\n",
    "\n",
    "    American ships have been sunk, American lives taken, in ways which it has stirred us very deeply to learn of, but the ships and people of other neutral and friendly nations have been sunk and overwhelmed in the waters in the same way. There has been no discrimination. The challenge is to all mankind.\n",
    "\n",
    "    Each nation must decide for itself how it will meet it. The choice we make for ourselves must be made with a moderation of counsel and temperateness of judgment befitting our character and our motives as a nation. We must put excited feeling away. Our motive will not be revenge or the victorious assertion of the physical might of the nation, but only the vindication of right, of human right, of which we are only a single champion.\n",
    "    \"\"\",  # Input text to be converted to speech\n",
    "        response_format=\"pcm\"            # Response format: PCM (Pulse Code Modulation)\n",
    "    ) as response:\n",
    "        # Iterate over the audio chunks in the response\n",
    "        for chunk in response.iter_bytes(1024):  # Read 1024 bytes at a time\n",
    "            stream.write(chunk)  # Write each chunk to the PyAudio stream for playback\n",
    "\n",
    "# Start streaming and playing the audio\n",
    "stream_audio()\n",
    "\n",
    "# Close the PyAudio stream properly\n",
    "stream.stop_stream()  # Stop the stream\n",
    "stream.close()        # Close the stream\n",
    "p.terminate()         # Terminate the PyAudio session\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Chat Completion and Assistant Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chat Completion to Audio with End-to-End Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Space exploration holds profound importance for a multitude of reasons, spanning scientific, technological, and inspirational domains. It drives technological advancements that often have wide-reaching applications on Earth, such as improvements in telecommunications, medical technologies, and materials science. Scientifically, it allows us to gain a deeper understanding of our universe, uncovering the mysteries of planetary systems, the nature of cosmic phenomena, and the origins of life itself. Space exploration also fosters international cooperation, uniting countries in common goals and shared missions. Moreover, it inspires generations of young minds to pursue careers in science, technology, engineering, and mathematics (STEM), thereby nurturing the innovators of tomorrow. Ultimately, exploring space addresses fundamental questions about our place in the cosmos and pushes the boundaries of human potential and curiosity."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create the chat completion request\n",
    "chat_completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",  # Specify the model to use\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},  # System message to set the assistant's behavior\n",
    "        {\"role\": \"user\", \"content\": \"Give me a paragraph about the importance of space exploration.\"}  # User message to initiate the conversation\n",
    "    ],\n",
    "    stream=True  # Enable streaming responses\n",
    ")\n",
    "\n",
    "# Function to stream the response\n",
    "def stream_response(chat_completion):\n",
    "    full_response = \"\"\n",
    "    display_id = display(HTML(full_response), display_id=True)\n",
    "    for chunk in chat_completion:\n",
    "        if chunk.choices[0].delta.content is not None:\n",
    "            full_response += chunk.choices[0].delta.content\n",
    "            display_id.update(HTML(full_response))\n",
    "\n",
    "# Call the function to stream the response\n",
    "stream_response(chat_completion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Space exploration holds paramount importance not only for the expansion of our knowledge but also for the survival and advancement of humanity. The exploration of space provides us the opportunity to discover and understand the mysteries of the cosmos, leading to remarkable scientific and technological advancements. It enables the development of new technologies and innovations that contribute to everyday life. Moreover, space exploration allows the possibility of searching for resources and perhaps even habitable planets, hence, presenting a potential solution for issues like overpopulation or resource scarcity. Furthermore, it fosters international collaboration and unites nations towards a common goal, thereby promoting peace and diplomacy. Hence, space exploration is a testament to human curiosity, ingenuity, and resilience, pushing the boundaries of what is currently known and understood."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Initialize PyAudio\n",
    "p = pyaudio.PyAudio()\n",
    "\n",
    "# Open a stream with specific audio format parameters\n",
    "stream = p.open(format=pyaudio.paInt16,\n",
    "    channels=1,\n",
    "    rate=24000,\n",
    "    output=True)\n",
    "\n",
    "# Create separate queues for text and audio chunks\n",
    "text_queue = queue.Queue()\n",
    "sentence_queue = queue.Queue()\n",
    "audio_queue = queue.Queue()\n",
    "\n",
    "# Flags for process control\n",
    "text_generation_complete = threading.Event()\n",
    "sentence_processing_complete = threading.Event()\n",
    "audio_generation_complete = threading.Event()\n",
    "\n",
    "def generate_and_display_text():\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": \"Give me a paragraph about the importance of space exploration.\"}\n",
    "        ],\n",
    "        stream=True\n",
    "    )\n",
    "    \n",
    "    full_response = \"\"\n",
    "    display_id = display(HTML(full_response), display_id=True)\n",
    "    \n",
    "    for chunk in chat_completion:\n",
    "        if chunk.choices[0].delta.content:\n",
    "            new_text = chunk.choices[0].delta.content\n",
    "            full_response += new_text\n",
    "            display_id.update(HTML(full_response))\n",
    "            text_queue.put(new_text)\n",
    "    \n",
    "    text_generation_complete.set()\n",
    "\n",
    "def process_sentences():\n",
    "    sentence_buffer = \"\"\n",
    "    while not (text_generation_complete.is_set() and text_queue.empty()):\n",
    "        try:\n",
    "            new_text = text_queue.get(timeout=0.1)\n",
    "            sentence_buffer += new_text\n",
    "            sentences = re.findall(r'[^.!?]+[.!?]', sentence_buffer)\n",
    "            for sentence in sentences:\n",
    "                sentence_queue.put(sentence.strip())\n",
    "            sentence_buffer = re.sub(r'.*[.!?]', '', sentence_buffer)\n",
    "        except queue.Empty:\n",
    "            continue\n",
    "    \n",
    "    if sentence_buffer:\n",
    "        sentence_queue.put(sentence_buffer.strip())\n",
    "    \n",
    "    sentence_processing_complete.set()\n",
    "\n",
    "def generate_audio():\n",
    "    while not (sentence_processing_complete.is_set() and sentence_queue.empty()):\n",
    "        try:\n",
    "            sentence = sentence_queue.get(timeout=0.5)\n",
    "            with client.audio.speech.with_streaming_response.create(\n",
    "                model=\"tts-1\",\n",
    "                voice=\"alloy\",\n",
    "                input=sentence,\n",
    "                response_format=\"pcm\"\n",
    "            ) as response:\n",
    "                for audio_chunk in response.iter_bytes(1024):\n",
    "                    audio_queue.put(audio_chunk)\n",
    "            \n",
    "            # Add a short pause between sentences\n",
    "            audio_queue.put(b'\\x00' * 4800)  # 0.1 seconds of silence at 24000 Hz\n",
    "        except queue.Empty:\n",
    "            continue\n",
    "    \n",
    "    audio_generation_complete.set()\n",
    "\n",
    "def play_audio():\n",
    "    audio_started = False\n",
    "    while not (audio_generation_complete.is_set() and audio_queue.empty()):\n",
    "        try:\n",
    "            audio_chunk = audio_queue.get(timeout=0.5)\n",
    "            stream.write(audio_chunk)\n",
    "            if not audio_started:\n",
    "                audio_started = True\n",
    "        except queue.Empty:\n",
    "            continue\n",
    "    \n",
    "\n",
    "# Start text generation and display in a separate thread\n",
    "text_thread = threading.Thread(target=generate_and_display_text)\n",
    "text_thread.start()\n",
    "\n",
    "# Start sentence processing in a separate thread\n",
    "sentence_thread = threading.Thread(target=process_sentences)\n",
    "sentence_thread.start()\n",
    "\n",
    "# Start audio generation in a separate thread\n",
    "audio_gen_thread = threading.Thread(target=generate_audio)\n",
    "audio_gen_thread.start()\n",
    "\n",
    "# Wait a short moment before starting audio playback\n",
    "time.sleep(1)\n",
    "\n",
    "# Start audio playback in a separate thread\n",
    "audio_play_thread = threading.Thread(target=play_audio)\n",
    "audio_play_thread.start()\n",
    "\n",
    "# Wait for all threads to complete\n",
    "text_thread.join()\n",
    "sentence_thread.join()\n",
    "audio_gen_thread.join()\n",
    "audio_play_thread.join()\n",
    "\n",
    "# Close the PyAudio stream properly\n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "p.terminate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assistant to Audio with End-to-end Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified event handler that will actually stream the response from the assistant\n",
    "class EventHandler(AssistantEventHandler):\n",
    "    \"\"\"Custom event handler for processing assistant events.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.results = []  # Initialize the results list\n",
    "\n",
    "    @override\n",
    "    def on_text_created(self, text) -> None:\n",
    "        \"\"\"Handle the event when text is first created.\"\"\"\n",
    "        # Print the created text to the console\n",
    "        print(\"\\nassistant text > \", end=\"\", flush=True)\n",
    "        # Append the created text to the results list\n",
    "        self.results.append(text)\n",
    "\n",
    "    @override\n",
    "    def on_text_delta(self, delta, snapshot):\n",
    "        \"\"\"Handle the event when there is a text delta (partial text).\"\"\"\n",
    "        # Print the delta value (partial text) to the console\n",
    "        print(delta.value, end=\"\", flush=True)\n",
    "        # Append the delta value to the results list\n",
    "        self.results.append(delta.value)\n",
    "\n",
    "    def on_tool_call_created(self, tool_call):\n",
    "        \"\"\"Handle the event when a tool call is created.\"\"\"\n",
    "        # Print the type of the tool call to the console\n",
    "        print(f\"\\nassistant tool > {tool_call.type}\\n\", flush=True)\n",
    "\n",
    "    def on_tool_call_delta(self, delta, snapshot):\n",
    "        \"\"\"Handle the event when there is a delta (update) in a tool call.\"\"\"\n",
    "        if delta.type == 'code_interpreter':\n",
    "            # Check if there is an input in the code interpreter delta\n",
    "            if delta.code_interpreter.input:\n",
    "                # Print the input to the console\n",
    "                print(delta.code_interpreter.input, end=\"\", flush=True)\n",
    "                # Append the input to the results list\n",
    "                self.results.append(delta.code_interpreter.input)\n",
    "            # Check if there are outputs in the code interpreter delta\n",
    "            if delta.code_interpreter.outputs:\n",
    "                # Print a label for outputs to the console\n",
    "                print(\"\\n\\noutput >\", flush=True)\n",
    "                # Iterate over each output and handle logs specifically\n",
    "                for output in delta.code_interpreter.outputs or []:\n",
    "                    if output.type == \"logs\":\n",
    "                        # Print the logs to the console\n",
    "                        print(f\"\\n{output.logs}\", flush=True)\n",
    "                        # Append the logs to the results list\n",
    "                        self.results.append(output.logs)\n",
    "                        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread and attach the file to the message\n",
    "thread = client.beta.threads.create(\n",
    "    messages=[\n",
    "    {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": \"Give me a paragraph on penguins.\",\n",
    "    }\n",
    "]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "assistant text > Penguins are fascinating, flightless birds known for their distinctive black-and-white plumage and waddling gait. Native primarily to the Southern Hemisphere, they are most commonly associated with the icy landscapes of Antarctica, though some species inhabit more temperate regions like the coasts of South Africa, New Zealand, and the Galápagos Islands. Penguins are superb swimmers, using their flippers to maneuver through water with remarkable speed and agility in search of fish, krill, and other marine organisms. Social by nature, they often live in large colonies called rookeries, which provide a dynamic social structure and collective protection against predators. These resilient birds are also known for their complex nesting behaviors and shared parental responsibilities, with many species taking turns incubating eggs and feeding their chicks. Penguins' unique adaptations, such as their dense feathers and layer of blubber, enable them to thrive in some of the planet's most extreme environments, showcasing the remarkable diversity and resilience of avian life."
     ]
    }
   ],
   "source": [
    "# Stream the output from our assistant\n",
    "with client.beta.threads.runs.stream(\n",
    "    thread_id=thread.id,\n",
    "    assistant_id=assistant.id,\n",
    "    event_handler=EventHandler(),\n",
    ") as stream:\n",
    "    stream.until_done()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Penguins are a unique and captivating group of flightless birds primarily found in the Southern Hemisphere, with a particular abundance in Antarctica. They are exceptional swimmers, utilizing their flipper-like wings and streamlined bodies to navigate through icy waters with remarkable agility. Penguins are highly social animals, often forming large colonies that can number in the thousands. These colonies provide protection and support, especially during the breeding season, when parents take turns incubating eggs and foraging for food. Adapted to some of the planet's harshest environments, penguins have developed insulating layers of fat and dense feathers to keep warm. Despite their clumsy waddling on land, their charismatic and endearing behavior, paired with their stark black-and-white plumage, endears them to people worldwide."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time  # Import time module for sleep functions\n",
    "import threading  # Import threading module for handling threads\n",
    "import queue  # Import queue module for creating queues\n",
    "import pyaudio  # Import PyAudio module for audio playback\n",
    "import re  # Import re module for regular expressions\n",
    "from openai import OpenAI  # Import OpenAI module for interacting with the OpenAI API\n",
    "from IPython.display import clear_output, display, Markdown  # Import display functions for Jupyter Notebooks\n",
    "\n",
    "# Initialize the OpenAI client\n",
    "client = OpenAI()\n",
    "\n",
    "# Define a custom event handler class that extends AssistantEventHandler\n",
    "class EventHandler(AssistantEventHandler):\n",
    "    def __init__(self):\n",
    "        super().__init__()  # Call the initializer of the parent class\n",
    "        self.results = []  # List to store text results\n",
    "        self.text_buffer = \"\"  # String buffer to collect text chunks\n",
    "        self.sentence_queue = queue.Queue()  # Queue to store sentences for processing\n",
    "        self.audio_queue = queue.Queue()  # Queue to store audio chunks for playback\n",
    "        self.text_generation_complete = threading.Event()  # Event to signal when text generation is complete\n",
    "\n",
    "        # Initialize PyAudio for audio playback\n",
    "        self.p = pyaudio.PyAudio()\n",
    "        self.stream = self.p.open(format=pyaudio.paInt16,  # Audio format\n",
    "            channels=1,  # Number of audio channels\n",
    "            rate=24000,  # Sample rate\n",
    "            output=True)  # Output mode\n",
    "\n",
    "        # Start threads for audio processing and playback\n",
    "        self.audio_processing_thread = threading.Thread(target=self.process_sentences)\n",
    "        self.audio_processing_thread.start()\n",
    "        self.audio_playback_thread = threading.Thread(target=self.play_audio)\n",
    "        self.audio_playback_thread.start()\n",
    "\n",
    "    # Method to handle incoming text deltas (partial responses)\n",
    "    def on_text_delta(self, delta, snapshot):\n",
    "        text = delta.value  # Extract text from delta\n",
    "        self.results.append(text)  # Add text to results\n",
    "        self.text_buffer += text  # Add text to buffer\n",
    "        self.process_text_buffer()  # Process the text buffer\n",
    "        self.update_output()  # Update the displayed output\n",
    "\n",
    "    # Method to process the text buffer and extract sentences\n",
    "    def process_text_buffer(self):\n",
    "        sentences = re.findall(r'[^.!?]+[.!?]', self.text_buffer)  # Find sentences in the buffer\n",
    "        for sentence in sentences:\n",
    "            self.sentence_queue.put(sentence.strip())  # Add sentences to the queue\n",
    "        self.text_buffer = re.sub(r'.*[.!?]', '', self.text_buffer)  # Remove processed sentences from the buffer\n",
    "\n",
    "    # Method to update the displayed output in a Jupyter Notebook\n",
    "    def update_output(self):\n",
    "        clear_output(wait=True)  # Clear previous output\n",
    "        markdown_content = \"\".join(self.results)  # Combine results into a single string\n",
    "        display(Markdown(markdown_content))  # Display the results as Markdown\n",
    "\n",
    "    # Method to process sentences from the queue and convert them to audio\n",
    "    def process_sentences(self):\n",
    "        while not self.text_generation_complete.is_set() or not self.sentence_queue.empty():\n",
    "            try:\n",
    "                sentence = self.sentence_queue.get(timeout=0.1)  # Get a sentence from the queue\n",
    "                with client.audio.speech.with_streaming_response.create(\n",
    "                    model=\"tts-1\",  # TTS model\n",
    "                    voice=\"onyx\",  # Voice\n",
    "                    input=sentence,  # Sentence to convert to speech\n",
    "                    response_format=\"pcm\"  # Audio format\n",
    "                ) as response:\n",
    "                    for audio_chunk in response.iter_bytes(1024):  # Stream audio chunks\n",
    "                        self.audio_queue.put(audio_chunk)  # Add audio chunks to the queue\n",
    "                # Add a short pause between sentences\n",
    "                self.audio_queue.put(b'\\x00' * 2400)  # 0.05 seconds of silence at 24000 Hz\n",
    "            except queue.Empty:\n",
    "                continue\n",
    "\n",
    "    # Method to play audio from the queue\n",
    "    def play_audio(self):\n",
    "        while not self.text_generation_complete.is_set() or not self.audio_queue.empty():\n",
    "            try:\n",
    "                audio_chunk = self.audio_queue.get(timeout=0.1)  # Get an audio chunk from the queue\n",
    "                self.stream.write(audio_chunk)  # Play the audio chunk\n",
    "            except queue.Empty:\n",
    "                continue\n",
    "\n",
    "        self.stream.stop_stream()  # Stop the audio stream\n",
    "        self.stream.close()  # Close the audio stream\n",
    "        self.p.terminate()  # Terminate PyAudio\n",
    "\n",
    "    # Method called when the text generation is complete\n",
    "    def on_end(self):\n",
    "        self.process_text_buffer()  # Process any remaining text in the buffer\n",
    "        if self.text_buffer:\n",
    "            self.sentence_queue.put(self.text_buffer.strip())  # Add remaining text to the queue\n",
    "        \n",
    "        self.text_generation_complete.set()  # Signal that text generation is complete\n",
    "        self.audio_processing_thread.join()  # Wait for the processing thread to finish\n",
    "        self.audio_playback_thread.join()  # Wait for the playback thread to finish\n",
    "\n",
    "# Create an assistant using the client library\n",
    "assistant = client.beta.assistants.create(\n",
    "    model=\"gpt-4o\",  # Assistant model\n",
    "    instructions=\"You are a helpful assistant.\",  # Instructions for the assistant\n",
    "    temperature=1,  # Sampling temperature\n",
    "    top_p=1,  # Top-p sampling\n",
    ")\n",
    "\n",
    "# Create a new assistant thread with an initial user message\n",
    "assistant_thread = client.beta.threads.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"Give me one paragraph on penguins\",  # Initial user message\n",
    "                },\n",
    "            ],\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create an instance of the custom event handler\n",
    "event_handler = EventHandler()\n",
    "\n",
    "# Stream the assistant's response\n",
    "with client.beta.threads.runs.stream(\n",
    "    thread_id=assistant_thread.id,  # ID of the assistant thread\n",
    "    assistant_id=assistant.id,  # ID of the assistant\n",
    "    event_handler=event_handler,  # Custom event handler\n",
    ") as stream:\n",
    "    stream.until_done()  # Stream responses until complete\n",
    "\n",
    "event_handler.on_end()  # Call the end method when streaming is complete\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NormalProgramming",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
